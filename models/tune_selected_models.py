import warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os
import torch
import json
import joblib

from pytorch_tabular import TabularModel
from pytorch_tabular.models import (
    TabNetModelConfig,
    DANetConfig,
    AutoIntConfig,
    TabTransformerConfig
)
from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig
from pytorch_tabular.models.common.heads import LinearHeadConfig
from pytorch_tabular.tabular_model_tuner import TabularModelTuner

def set_seed(seed=42):
    """Set all random seeds for reproducibility"""
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def tune_selected_models(data_path):
    # Create results directory if it doesn't exist
    os.makedirs("results", exist_ok=True)
    
    # Set random seed
    set_seed(42)

    # Read data
    df = pd.read_excel(data_path)
    features = [c for c in df.columns if c.startswith("Feature")]
    X = df[features].copy()
    y = df["Label"].copy()

    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)    
    # Save the scaler
    joblib.dump(scaler, "results/scaler.pkl")
    print("âœ… Saved scaler to results/scaler.pkl")

    # Split data into train and test sets (80/20)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # å‡†å¤‡è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_df = X_train.copy()
    train_df['target'] = y_train
    test_df = X_test.copy()
    test_df['target'] = y_test
    
    # Save test set
    test_df.to_csv("results/test_set.csv", index=False)
    print("âœ… Saved test set to results/test_set.csv")

    print("\nData Shape:", X.shape)
    print("Label Distribution:\n", y.value_counts())
    print("\nTrain Shape:", X_train.shape)
    print("Test Shape:", X_test.shape)

    # Configure data
    data_config = DataConfig(
        target=['target'],
        continuous_cols=features,
        categorical_cols=[],
    )

    # é…ç½®è®­ç»ƒå™¨
    trainer_config = TrainerConfig(
        batch_size=1024,
        max_epochs=200,  # å¢åŠ è®­ç»ƒè½®æ•°
        early_stopping="valid_loss",
        early_stopping_patience=20  # å¢åŠ æ—©åœè€å¿ƒå€¼
    )

    optimizer_config = OptimizerConfig(
        optimizer="Adam",
        optimizer_params={"lr": 0.001, "weight_decay": 0.01},
        lr_scheduler="ReduceLROnPlateau",
        lr_scheduler_params={"mode": "min", "patience": 5, "factor": 0.1},
        lr_scheduler_monitor_metric="valid_loss"
    )

    # Configure head with more options
    head_config = LinearHeadConfig(
        layers="256-128-64",  # æ·»åŠ æ›´å¤šå±‚
        dropout=0.2,
        initialization="kaiming",
        use_batch_norm=True
    ).__dict__

    # å®šä¹‰è¦è°ƒä¼˜çš„æ¨¡å‹é…ç½®
    model_configs = [
        # 1. DANet
        DANetConfig(
            task="classification",
            head="LinearHead",
            head_config=head_config,
            metrics=["accuracy", "auroc"],
            metrics_params=[{}, {}],
            metrics_prob_input=[False, True],
            n_layers=6,
            abstlay_dim_1=32,
            abstlay_dim_2=64,
            dropout_rate=0.1
        ),
        # 2. TabTransformer
        TabTransformerConfig(
            task="classification",
            head="LinearHead",
            head_config=head_config,
            metrics=["accuracy", "auroc"],
            metrics_params=[{}, {}],
            metrics_prob_input=[False, True],
            input_embed_dim=32,
            embedding_initialization="kaiming_uniform",
            embedding_bias=False,
            share_embedding=False,
            share_embedding_strategy="fraction",
            shared_embedding_fraction=0.25,
            num_heads=8,
            num_attn_blocks=6,
            embedding_dropout=0.1,
            transformer_head_dim=None,
            attn_dropout=0.1,
            add_norm_dropout=0.1,
            ff_dropout=0.1,
            ff_hidden_multiplier=4,
            transformer_activation="GEGLU",
            batch_norm_continuous_input=True
        ),
        # 3. AutoInt
        AutoIntConfig(
            task="classification",
            head="LinearHead",
            head_config=head_config,
            metrics=["accuracy", "auroc"],
            metrics_params=[{}, {}],
            metrics_prob_input=[False, True],
            embedding_dim=63,  # ä¸ layers çš„ç¬¬ä¸€å±‚ç»´åº¦åŒ¹é…
            attn_embed_dim=16,  # ä¸ layers çš„æœ€åä¸€å±‚ç»´åº¦åŒ¹é…
            # num_heads=2,
            num_attn_blocks=3,
            attn_dropouts=0.0,
            has_residuals=True,
            batch_norm_continuous_input=True,
            embedding_initialization="kaiming_uniform",
            embedding_bias=True,
            share_embedding=True,
            share_embedding_strategy="add",
            shared_embedding_fraction=0.25,
            deep_layers=False,
            # layers="63-24-16",  # ä»åµŒå…¥ç»´åº¦(32)åˆ°æ³¨æ„åŠ›ç»´åº¦(16)
            use_batch_norm=True,
            attention_pooling=True
        ),
        # 4. TabNet
        TabNetModelConfig(
            task="classification",
            head="LinearHead",
            head_config=head_config,
            metrics=["accuracy", "auroc"],
            metrics_params=[{}, {}],
            metrics_prob_input=[False, True],
            n_d=32,
            n_a=32,
            n_steps=3,
            gamma=1.5,
            n_independent=1,
            n_shared=2
        )
    ]

    # ä¸ºæ¯ä¸ªæ¨¡å‹å®šä¹‰æœç´¢ç©ºé—´
    search_spaces = [
        # DANet
        {
            "optimizer_config__optimizer": ["Adam", "AdamW"],
            "optimizer_config__optimizer_params": [
                {"weight_decay": 0.01},
                {"weight_decay": 0.001}
            ],
            "model_config__n_layers": [4, 6, 8],  # å¢åŠ å±‚æ•°é€‰é¡¹
            "model_config__abstlay_dim_1": [16, 32, 64],  # å¢åŠ ç»´åº¦é€‰é¡¹
            "model_config__abstlay_dim_2": [32, 64, 128],  # å¢åŠ ç»´åº¦é€‰é¡¹
            "model_config__k": [3, 5, 7],  # å¢åŠ  k å€¼é€‰é¡¹
            "model_config__dropout_rate": [0.0, 0.1, 0.2],  # å¢åŠ  dropout é€‰é¡¹
            "model_config__block_activation": ["ReLU", "LeakyReLU", "GELU"],  # å¢åŠ æ¿€æ´»å‡½æ•°é€‰é¡¹
            "model_config__virtual_batch_size": [128, 256, 512]  # å¢åŠ æ‰¹é‡å¤§å°é€‰é¡¹
        },
        # TabTransformer
        {
            "optimizer_config__optimizer": ["Adam", "AdamW"],
            "optimizer_config__optimizer_params": [
                {"weight_decay": 0.01},
                {"weight_decay": 0.001}
            ],
            "model_config__input_embed_dim": [16, 32, 64],  # å¢åŠ åµŒå…¥ç»´åº¦é€‰é¡¹
            "model_config__num_attn_blocks": [2, 4, 6],  # å¢åŠ æ³¨æ„åŠ›å—æ•°é‡
            "model_config__num_heads": [4, 8, 16],  # å¢åŠ å¤´æ•°é€‰é¡¹
            "model_config__transformer_head_dim": [None, 16, 32],  # å¢åŠ å¤´ç»´åº¦é€‰é¡¹
            "model_config__attn_dropout": [0.0, 0.1, 0.2],  # å¢åŠ æ³¨æ„åŠ›dropouté€‰é¡¹
            "model_config__add_norm_dropout": [0.0, 0.1, 0.2],  # å¢åŠ å½’ä¸€åŒ–dropouté€‰é¡¹
            "model_config__ff_dropout": [0.0, 0.1, 0.2],  # å¢åŠ å‰é¦ˆdropouté€‰é¡¹
            "model_config__ff_hidden_multiplier": [2, 4, 8],  # å¢åŠ éšè—å±‚å€æ•°é€‰é¡¹
            "model_config__transformer_activation": ["GEGLU", "ReGLU", "SwiGLU"],  # ä½¿ç”¨æ”¯æŒçš„æ¿€æ´»å‡½æ•°
            "model_config__embedding_initialization": ["kaiming_uniform", "kaiming_normal"],
            "model_config__embedding_bias": [True, False],
            "model_config__embedding_dropout": [0.0, 0.1, 0.2],
            "model_config__share_embedding": [True, False],
            "model_config__share_embedding_strategy": ["add", "fraction"],
            "model_config__shared_embedding_fraction": [0.25, 0.5, 0.75]
        },
        # AutoInt
        {
            "optimizer_config__optimizer": ["Adam", "AdamW"],
            "optimizer_config__optimizer_params": [
                {"weight_decay": 0.01},
                {"weight_decay": 0.001}
            ],
            "model_config__embedding_dim": [63, 32, 16],  # å›ºå®šä¸ºè¾“å…¥ç»´åº¦
            "model_config__attn_embed_dim": [16, 32, 64],  # æ³¨æ„åŠ›å±‚ç»´åº¦é€‰é¡¹
            "model_config__num_heads": [2, 4, 8],
            "model_config__num_attn_blocks": [2, 3, 4],
            "model_config__attn_dropouts": [0.0, 0.1, 0.2],
            "model_config__has_residuals": [True, False],
            "model_config__embedding_initialization": ["kaiming_uniform", "kaiming_normal"],
            "model_config__embedding_bias": [True, False],
            "model_config__share_embedding": [True, False],
            "model_config__share_embedding_strategy": ["add", "fraction"],
            "model_config__shared_embedding_fraction": [0.25, 0.5],
            "model_config__deep_layers": [False],
            "model_config__use_batch_norm": [True],
            "model_config__attention_pooling": [True, False],
            "model_config__activation": ["ReLU", "LeakyReLU"],  # æ·»åŠ æ¿€æ´»å‡½æ•°é€‰é¡¹
            "model_config__initialization": ["kaiming", "xavier"],  # æ·»åŠ åˆå§‹åŒ–æ–¹æ³•é€‰é¡¹
            "model_config__dropout": [0.0, 0.1, 0.2]  # æ·»åŠ dropouté€‰é¡¹
        },
        # TabNet
        {
            "optimizer_config__optimizer": ["Adam", "AdamW"],
            "optimizer_config__optimizer_params": [
                {"weight_decay": 0.01},
                {"weight_decay": 0.001}
            ],
            "model_config__n_d": [8, 16, 32, 64],  # é¢„æµ‹å±‚ç»´åº¦ (4-64)
            "model_config__n_a": [8, 16, 32, 64],  # æ³¨æ„åŠ›å±‚ç»´åº¦ (4-64)
            "model_config__n_steps": [3, 5, 7, 10],  # ç½‘ç»œæ­¥éª¤æ•° (3-10)
            "model_config__gamma": [1.0, 1.3, 1.5, 2.0],  # æ³¨æ„åŠ›æ›´æ–°çš„ç¼©æ”¾å› å­ (1.0-2.0)
            "model_config__n_independent": [1, 2, 3],  # ç‹¬ç«‹ GLU å±‚æ•°
            "model_config__n_shared": [1, 2, 3],  # å…±äº« GLU å±‚æ•°
            "model_config__virtual_batch_size": [128, 256, 512],  # Ghost Batch Normalization çš„æ‰¹é‡å¤§å°
            "model_config__mask_type": ["sparsemax", "entmax"],  # æ©ç å‡½æ•°ç±»å‹
            "model_config__batch_norm_continuous_input": [True],
            "model_config__embedding_dropout": [0.0, 0.1, 0.2]  # åµŒå…¥å±‚çš„ dropout ç‡
        }
    ]

    # åŠ è½½å†å²æœ€ä½³é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    best_configs_file = 'results/best_configs.json'
    historical_best = {}
    if os.path.exists(best_configs_file):
        try:
            with open(best_configs_file, 'r') as f:
                historical_best = json.load(f)
            print("\nLoaded historical best configurations")
        except json.JSONDecodeError:
            print("\nWarning: best_configs.json is corrupted, starting fresh")
            historical_best = {}

    print("\nStarting Hyperparameter Tuning...")
    
    all_tuning_results = []
    best_models = {}
    summary_results = []
    
    # æŒ‰é¡ºåºè°ƒä¼˜æ¯ä¸ªæ¨¡å‹
    model_names = ["DANetModel", "TabTransformerModel", "AutoIntModel", "TabNetModel"]
    for model_idx, (model_config, search_space) in enumerate(zip(model_configs, search_spaces)):
        model_name = model_names[model_idx]
        print(f"\nTuning {model_name}...")
        
        tuner = TabularModelTuner(
            data_config=data_config,
            model_config=model_config,
            optimizer_config=optimizer_config,
            trainer_config=trainer_config
        )

        tuner_df = tuner.tune(
            train=train_df,
            validation=test_df,  # ä½¿ç”¨æµ‹è¯•é›†ä½œä¸ºéªŒè¯é›†
            search_space=search_space,
            strategy="random_search",
            n_trials=2,  # æ¯ä¸ªæ¨¡å‹2æ¬¡å°è¯•
            metric="auroc",  # ä½¿ç”¨aurocä½œä¸ºä¸»è¦ä¼˜åŒ–æŒ‡æ ‡
            mode="max",
            progress_bar=True,
            verbose=True,
            return_best_model=True  # ç¡®ä¿è¿”å›æœ€ä½³æ¨¡å‹
        )
        
        # ä¿å­˜æ¯ä¸ªæ¨¡å‹çš„è°ƒä¼˜ç»“æœ
        tuner_df.trials_df['model'] = model_name
        all_tuning_results.append(tuner_df.trials_df)
        
        if tuner_df.best_model is not None:
            best_models[model_name] = tuner_df.best_model
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            model_save_path = f"results/{model_name}_best.pt"
            tuner_df.best_model.save_model(model_save_path)
            print(f"âœ… Saved best model to {model_save_path}")
        
        # è·å–æœ€ä½³ç»“æœ
        best_trial = tuner_df.trials_df.sort_values("auroc", ascending=False).iloc[0]
        
        # è·å–æœ€ä½³æ€§èƒ½æŒ‡æ ‡
        best_auc = best_trial["auroc"]
        best_acc = best_trial.get("accuracy", None)  # å°è¯•è·å–accuracy
        
        print(f"\nResults for {model_name}:")
        print(f"Best AUC: {best_auc:.4f}")
        if best_acc is not None:
            print(f"Accuracy at best AUC: {best_acc:.4f}")
        
        print("\nTop 3 configurations by AUC:")
        print(tuner_df.trials_df.sort_values("auroc", ascending=False).head(3))
        
        # å¦‚æœæ€§èƒ½æå‡ï¼Œæ›´æ–°å†å²æœ€ä½³
        if model_name not in historical_best or best_auc > historical_best[model_name]['performance']['auc']:
            # è½¬æ¢å‚æ•°å€¼ä¸ºPythonåŸç”Ÿç±»å‹
            params_dict = {}
            for col in best_trial.index:
                if 'model_config__' in col or 'optimizer_config__' in col:
                    value = best_trial[col]
                    # è½¬æ¢numpy/pandasç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
                    if isinstance(value, (np.integer, np.floating)):
                        value = value.item()
                    elif isinstance(value, np.bool_):
                        value = bool(value)
                    elif isinstance(value, dict):
                        # å¤„ç†å­—å…¸ä¸­çš„numpyç±»å‹
                        value = {k: v.item() if isinstance(v, (np.integer, np.floating, np.bool_)) else v 
                               for k, v in value.items()}
                    params_dict[col] = value
            
            historical_best[model_name] = {
                'params': params_dict,
                'performance': {
                    'auc': float(best_auc),
                    'accuracy': float(best_acc) if best_acc is not None else 0.0,
                    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                }
            }
            print(f"\nğŸ† New best configuration found for {model_name}!")
        
        # æ·»åŠ åˆ°æ±‡æ€»ç»“æœ
        summary_results.append({
            "model_name": model_name,
            "best_auroc": best_auc,
            "accuracy_at_best_auroc": best_acc if best_acc is not None else 0.0,
            "historical_best_auroc": historical_best[model_name]['performance']['auc'],
            "historical_best_accuracy": historical_best[model_name]['performance']['accuracy'],
            "historical_best_timestamp": historical_best[model_name]['performance'].get('timestamp', 'N/A')
        })
    
    # åˆå¹¶æ‰€æœ‰è°ƒä¼˜ç»“æœ
    combined_tuning_df = pd.concat(all_tuning_results, ignore_index=True)
    combined_tuning_df.to_csv('results/all_trials.csv', index=False)
    print("âœ… Saved all trials to results/all_trials.csv")
    
    # ä¿å­˜å†å²æœ€ä½³é…ç½®
    with open(best_configs_file, 'w') as f:
        json.dump(historical_best, f, indent=4)
    print("âœ… Saved historical best configurations to results/best_configs.json")
    
    # åˆ›å»ºæ±‡æ€»DataFrame
    summary_df = pd.DataFrame(summary_results)
    summary_df.to_csv('results/summary.csv', index=False)
    print("âœ… Saved summary to results/summary.csv")
    
    # æ‰“å°æ±‡æ€»ç»“æœ
    print("\nModel Performance Summary:")
    print("=" * 80)
    for _, row in summary_df.iterrows():
        print(f"\nModel: {row['model_name']}")
        print(f"Current Best AUROC: {row['best_auroc']:.4f} (Accuracy: {row['accuracy_at_best_auroc']:.4f})")
        print(f"Historical Best AUROC: {row['historical_best_auroc']:.4f} (Accuracy: {row['historical_best_accuracy']:.4f})")
        print(f"Historical Best Achieved: {row['historical_best_timestamp']}")
    print("=" * 80)
    
    return combined_tuning_df, summary_df, best_models, historical_best

if __name__ == "__main__":
    data_path = "data/AI4healthcare.xlsx"
    tuner_df, summary_df, best_models, historical_best = tune_selected_models(data_path) 